{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PG1KI7wmDAB"
      },
      "source": [
        "1. Bag of Words Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_g9NIl2nmGgI",
        "outputId": "9c3964bd-7ae9-4cde-a5bd-5a7b167fdcf0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in c:\\users\\lphuu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.1.1)\n",
            "Requirement already satisfied: absl-py in c:\\users\\lphuu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras) (2.1.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\lphuu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras) (1.26.4)\n",
            "Requirement already satisfied: rich in c:\\users\\lphuu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras) (13.7.0)\n",
            "Requirement already satisfied: namex in c:\\users\\lphuu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras) (0.0.7)\n",
            "Requirement already satisfied: h5py in c:\\users\\lphuu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras) (3.10.0)\n",
            "Requirement already satisfied: optree in c:\\users\\lphuu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras) (0.11.0)\n",
            "Requirement already satisfied: ml-dtypes in c:\\users\\lphuu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras) (0.3.2)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\lphuu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from optree->keras) (4.9.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\lphuu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\lphuu\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras) (2.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\lphuu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install keras\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nO97jwBDmDAD"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'keras.preprocessing.text'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tokenizer\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras.preprocessing.text'"
          ]
        }
      ],
      "source": [
        "from keras.preprocessing.text import Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hGmK_4JrmDAE"
      },
      "outputs": [],
      "source": [
        "text = ['There was a man',\n",
        "        'The man had a dog',\n",
        "        'The dog and the man walker']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4ELzeLrEmcts"
      },
      "outputs": [],
      "source": [
        "model = Tokenizer()\n",
        "model.fit_on_texts(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Li8I0jO8muCA",
        "outputId": "0cac13af-2caf-4e5c-8188-f979864a62be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Key : ['man', 'the', 'a', 'dog', 'there', 'was', 'had', 'and', 'walker']\n",
            "[[0. 1. 0. 1. 0. 1. 1. 0. 0. 0.]\n",
            " [0. 1. 1. 1. 1. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 2. 0. 1. 0. 0. 0. 1. 1.]]\n"
          ]
        }
      ],
      "source": [
        "print(f\"Key : {list(model.word_index.keys())}\")\n",
        "rep = model.texts_to_matrix(text, mode = 'count')\n",
        "print(rep)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5C5xSyQmDAE"
      },
      "source": [
        "2. Create a Bag of Words Model with Sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "uAH1QosfnaKu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4cIqMSzonpxE"
      },
      "outputs": [],
      "source": [
        "sentence_1 = \"This is a good job. I will not miss it for anything\"\n",
        "sentence_2 = \"This is not good at all\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4alHyiwAn3KD"
      },
      "outputs": [],
      "source": [
        "CountVec = CountVectorizer(ngram_range=(1, 1), stop_words= 'english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UACF6G0koEcT",
        "outputId": "f49918ae-6230-4de4-de41-52e37aba0de9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CountVectorizer(stop_words='english')\n",
            "  (0, 0)\t1\n",
            "  (0, 1)\t1\n",
            "  (0, 2)\t1\n",
            "  (1, 0)\t1\n"
          ]
        }
      ],
      "source": [
        "#Transform\n",
        "Count_data = CountVec.fit_transform([sentence_1, sentence_2])\n",
        "print(CountVec)\n",
        "print(Count_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxTTN_pvobxj",
        "outputId": "8e6b9762-330f-4206-f2ef-4789a6bfbec7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   good  job  miss\n",
            "0     1    1     1\n",
            "1     1    0     0\n"
          ]
        }
      ],
      "source": [
        "cv_dataframe = pd.DataFrame(Count_data.toarray(), columns= CountVec.get_feature_names_out())\n",
        "print(cv_dataframe)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8Sn2qu_mDAE"
      },
      "source": [
        "3. Feature Extraction with TF - IDF vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "pl_-IfGfpsIo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Va4karStrV21"
      },
      "outputs": [],
      "source": [
        "sentence_1 = \"This is a good job. I will not miss it for anything\"\n",
        "sentence_2 = \"This is not good at all\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9jv6iHkreLW",
        "outputId": "ea02e5a1-8191-411f-cc3f-a6beeacc7d73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Without Smoothing:\n"
          ]
        }
      ],
      "source": [
        "# Without smooth IDF\n",
        "print(\"Without Smoothing:\")\n",
        "# Define TF - IDF\n",
        "tf_idf_vec = TfidfVectorizer(use_idf= True, smooth_idf= False,\n",
        "                             ngram_range=(1,1), stop_words = 'english') # to use only bigrams ngram_range=(2,2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "F8nqUOT1sItb"
      },
      "outputs": [],
      "source": [
        "# Transform\n",
        "tf_idf_data = tf_idf_vec.fit_transform([sentence_1, sentence_2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uvfg8GomtVaD",
        "outputId": "1c819928-bd60-4df7-c913-be86d25b3a55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "       good       job      miss\n",
            "0  0.385372  0.652491  0.652491\n",
            "1  1.000000  0.000000  0.000000\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Create dataframe\n",
        "tf_idf_dataframe = pd.DataFrame(tf_idf_data.toarray(), columns = tf_idf_vec.get_feature_names_out())\n",
        "print(tf_idf_dataframe)\n",
        "print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "8zaq58MiywMC"
      },
      "outputs": [],
      "source": [
        "# With smooth\n",
        "tf_idf_vec_smooth = TfidfVectorizer(use_idf=True,\n",
        "                                    smooth_idf=True,\n",
        "                                    ngram_range=(1,1),\n",
        "                                    stop_words='english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "SCsDSW_q04hN"
      },
      "outputs": [],
      "source": [
        "tf_idf_data_smooth = tf_idf_vec_smooth.fit_transform([sentence_1, sentence_2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDJjZOVS1XoL",
        "outputId": "62a3d3c7-5c8b-4402-f012-47d2a989d845"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "With Smoothing:\n",
            "       good       job      miss\n",
            "0  0.449436  0.631667  0.631667\n",
            "1  1.000000  0.000000  0.000000\n"
          ]
        }
      ],
      "source": [
        "print(\"With Smoothing:\")\n",
        "tf_idf_dataframe_smooth = pd.DataFrame(tf_idf_data_smooth.toarray(), columns=tf_idf_vec_smooth.get_feature_names_out())\n",
        "print(tf_idf_dataframe_smooth)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MIQaD6YmDAE"
      },
      "source": [
        "4. Supervied Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spJJNZ2bmDAE"
      },
      "source": [
        "4.1 EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "VKkYUoIR6lB-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "oYxG3pfr7Lu-",
        "outputId": "b5540b33-caf7-4575-bb9b-c642e5b4310a"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "**bold**"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import Markdown, display\n",
        "def printmd(string):\n",
        "  display(Markdown(string))\n",
        "printmd('**bold**')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7DkpORTU7pW_"
      },
      "outputs": [],
      "source": [
        "data_path = \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rhkAbS2mDAE"
      },
      "source": [
        "4.1.1 Checking for missing values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "An0y1IZ7mDAE"
      },
      "source": [
        "4.1.2 Calculating number of comments under each label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mANx7mu_mDAE"
      },
      "source": [
        "4.1.3 Calculating number of comments having multiple labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaHlP6N6mDAF"
      },
      "source": [
        "4.1.4 WordCloud representation of most used words in each category of comments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USGi6ihMmDAF"
      },
      "source": [
        "4.2 Data Pre - Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0sQF-QEmDAF"
      },
      "source": [
        "4.2.1 Cleaning Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgreJnJnmDAF"
      },
      "source": [
        "4.2.2 Removing Stop Words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DINrcUgmDAF"
      },
      "source": [
        "4.2.3 Stemming"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxt6lqNNmDAF"
      },
      "source": [
        "4.2.4 Train - Test Split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRAxak52mDAF"
      },
      "source": [
        "4.2.5 TF - IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGYE9SBqmDAF"
      },
      "source": [
        "4.3 Multi - Label Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3XjskORmDAF"
      },
      "source": [
        "4.3.1 Multiple Binary Classifications - (One Vs Rest Classifier)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XGvDMJ7mDAF"
      },
      "source": [
        "4.3.2 Multiple Binary Classifications - (Binary Relevance)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usF989JYmDAF"
      },
      "source": [
        "4.3.3 Classifier Chanins"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWT1pcrkmDAF"
      },
      "source": [
        "4.3.4 Label Powerset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQ6MeaNzmDAF"
      },
      "source": [
        "4.3.5 Adapted Algorithm"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
